{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn and Run\n",
    "This notebook trains all the models and uses them to generate a reply from a comment. Given a reasonable number of comments and not great computing power, the models will take a large amount of time to train.\n",
    "\n",
    "First, we will need nltk again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.3\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from operator import itemgetter\n",
    "\n",
    "import numpy as np\n",
    "import pickle\n",
    "import keras\n",
    "\n",
    "import nltk\n",
    "nltk.download('vader_lexicon')\n",
    "\n",
    "from keras.preprocessing import sequence\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "To make thing simpler to write, the following scripts will load the data from the correct locations, train the models, and them save the models to the model directory. See the individual files for information on each model. Hopefull a model summary will be implemented soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all the models needed for generating comments and save them.\n",
    "# These take awhile. So avoid running these if possible.\n",
    "!python3 scripts/train/next_word_markov_model.py\n",
    "!python3 scripts/train/predict_first_word_model.py\n",
    "!python3 scripts/train/predict_upvotes_model.py\n",
    "!python3 scripts/train/cluster_comments.py\n",
    "!python3 scripts/train/cluster_markov_model.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Models\n",
    "With the models trained, we can load each of them from the models directory to be used in the comment generator. Then we then load some files to make generating readable comment possible. Each of the models does a follows:\n",
    "\n",
    "    predict_upvotes                 ====>        Predicts the upvotes of a comment \n",
    "    predict_first_word              ====>        Predicts the first word of child of the comment\n",
    "    cluster_comments                ====>        Clusters the comments into 256 different clusters\n",
    "    cluster_markov                  ====>        Given the cluster of the parent, generates a probability\n",
    "                                                   distribution for the words in the child\n",
    "    generator_probability_chain     ====>        generates a bigram based probability distribution for the next word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all models, data, words, and tokenizer\n",
    "predict_upvote_model = keras.models.load_model(\"models/predict_upvotes.h5\")\n",
    "predict_first_word_model = keras.models.load_model(\"models/predict_first_word.h5\")\n",
    "cluster_comments_model = joblib.load(open(\"models/cluster_comments.pkl\", 'rb'))\n",
    "cluster_markov_model = pickle.load(open(\"models/cluster_markov_model.pkl\", 'rb'))\n",
    "p_chain = pickle.load(open(\"models/generator_probability_chain.pkl\", 'rb'))\n",
    "\n",
    "comment_texts = np.load(\"cleaned/comment_texts.npy\")\n",
    "comment_sentiment_scores = np.load(\"cleaned/comment_sentiment_scores.npy\")\n",
    "words = pickle.load(open(\"cleaned/words.pkl\", \"rb\"))\n",
    "inv_map = {v: k for k, v in words.items()}\n",
    "tokenizer = pickle.load(open(\"tokenizer.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comment Generation\n",
    "Now we can use all the models to generate a comment in a upvote maximizing way. To see the procedure for generating a comment, see the presentation in the main directory. We show both the parent comment and the generated reply. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment = damn even here you're everywhere\n",
      "\n",
      "reply = grep the term spyware like saying plagiarism is okay\n"
     ]
    }
   ],
   "source": [
    "# Using all the previously described models and data to generate a random comment reply.\n",
    "cmt = random.randint(0, comment_texts.shape[0])\n",
    "print(\"comment = {}\\n\".format(\n",
    "            \" \".join([inv_map[ind] for ind in [word for word in comment_texts[cmt] if word != 0]])))\n",
    "\n",
    "print(\"reply = {}\".format(generate_comment(comment_texts[cmt], comment_sentiment_scores[cmt],\n",
    "                                           inv_map, p_chain,\n",
    "                                           upvote_model=predict_upvote_model,\n",
    "                                           first_word_model=predict_first_word_model,\n",
    "                                           comment_cluster_model=cluster_comments_model,\n",
    "                                           cluster_markov_model=cluster_markov_model,\n",
    "                                           tokenizer=tokenizer\n",
    "                                           )\n",
    "                         )\n",
    "     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
