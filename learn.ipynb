{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting nltk\n",
      "Requirement already satisfied: six in /opt/conda/lib/python3.6/site-packages (from nltk)\n",
      "Installing collected packages: nltk\n",
      "Successfully installed nltk-3.3\n",
      "\u001b[33mYou are using pip version 9.0.3, however version 10.0.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n",
      "  warnings.warn(\"The twython library has not been installed. \"\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from operator import itemgetter\n",
    "\n",
    "import pickle\n",
    "import keras\n",
    "from keras.preprocessing import sequence\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train all the models needed for generating comments and save them.\n",
    "# These take awhile. So avoid running these if possible.\n",
    "!python3 next_word_markov_model.py\n",
    "!python3 predict_first_word_model.py\n",
    "!python3 pedict_upvotes_model.py\n",
    "!python3 cluster_comments.py\n",
    "!python3 cluster_markov_model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The generate_comment function generates a comment under the following premise.\n",
    "# If a upvote model is provided, then we use the model to evaluate n comments\n",
    "#  and chose the max. Otherwise we choose the first word generated\n",
    "# If a first word model is provided, we use it to generate the seed. Otherwise,\n",
    "#  the seed is randomly selected.\n",
    "# If cluster model, a cluster markov model, and a tokenizer are provided\n",
    "#  then we weight the next word probability distribution by distribution\n",
    "#  generated by the cluster model. This attempts to push the model to\n",
    "#  generate a on topic reply\n",
    "# The generated comment is returned as a string\n",
    "def generate_comment(parent_text, parent_sentiment_score,\n",
    "                     words, generate_chain,\n",
    "                     upvote_model=None, first_word_model=None,\n",
    "                     comment_cluster_model=None, cluster_markov_model=None,\n",
    "                     tokenizer=None, n=3, threshold=10):\n",
    "    \n",
    "    vader_analyzer = SentimentIntensityAnalyzer()\n",
    "    if (comment_cluster_model is not None\n",
    "        and cluster_markov_model is not None\n",
    "        and tokenizer is not None):\n",
    "            parent = \" \".join([words[ind] for ind in parent_text if ind != 0])\n",
    "            tokened_parent = tokenizer.texts_to_matrix(parent, mode=\"tfidf\")\n",
    "            cluster = comment_cluster_model.predict(tokened_parent)[0]\n",
    "            parent_distribution = np.insert(cluster_markov_model[cluster], 0, 0)\n",
    "    else:\n",
    "        parent_distribution = None\n",
    "    if first_word_model is None:\n",
    "        choice = np.random.choice(chain[(0, 0)])\n",
    "    else:\n",
    "        choice = first_word_model_choice(parent_text,\n",
    "                                         parent_sentiment_score,\n",
    "                                         generate_chain,\n",
    "                                         first_word_model, threshold)\n",
    "    comment = np.array([0, 0, choice])\n",
    "    while comment[-1] != -1 and len(comment) < 50: \n",
    "            #try:\n",
    "            access_val = make_pdist(generate_chain[(comment[-2], comment[-1])], 10000)\n",
    "            if upvote_model is not None:\n",
    "                choice = upvote_model_choice(comment, access_val, words,\n",
    "                                             generate_chain, vader_analyzer,\n",
    "                                             upvote_model, n, parent_distribution)\n",
    "            else:\n",
    "                    choice = choose(access_val)                \n",
    "            comment = np.append(comment, choice)\n",
    "    return \" \".join([words[ind] for ind in comment[2:-1]])\n",
    "  \n",
    "\n",
    "# Given a dictionary representing a probability distribution\n",
    "# and the size of the probability distibution returns the\n",
    "# a np array representation of the probability distribution\n",
    "def make_pdist(pchain, vocab_size):\n",
    "    temp = np.zeros(vocab_size + 1)\n",
    "    for index, prob in pchain.items():\n",
    "        temp[index + 1] = prob\n",
    "    return temp\n",
    "\n",
    "# If a parent distribution is provided, the current distribution\n",
    "# is weighted by the parent distribution and then a choice is made\n",
    "# from this new distribution. Otherwise a a choice is made from the\n",
    "# current distribution\n",
    "def choose(c_dist, p_dist=None):\n",
    "    if p_dist is not None:\n",
    "        p_dist[0] = c_dist[0] ** 2\n",
    "        new_dist = p_dist * c_dist\n",
    "        new_dist = new_dist / np.sum(new_dist)\n",
    "    else:\n",
    "        new_dist = c_dist\n",
    "    return np.random.choice(np.arange(new_dist.shape[-1]), p=new_dist) - 1\n",
    "\n",
    "# Uses the given local variables to generate threshold number of canidate words,\n",
    "# and selects one that maximizes the upvotes predicted by the upvote predict model.\n",
    "def upvote_model_choice(comment, access_val, word_index, chain,\n",
    "                        vader_analyzer, upvote_model, threshold, parent_dist):\n",
    "    choices = []\n",
    "    chosen = []\n",
    "    for i in range(0, threshold):\n",
    "        choice = choose(access_val, parent_dist)            \n",
    "        if choice in chosen:\n",
    "            choice = choose(access_val, parent_dist)\n",
    "        if choice == -1:\n",
    "            comment_text = \" \".join([word_index[ind] for ind in comment[2:]])\n",
    "        else:\n",
    "            comment_text = \" \".join([word_index[ind] for ind in np.append(comment[2:], choice)])\n",
    "        text_scores = vader_analyzer.polarity_scores(comment_text)\n",
    "        text_scores_lst = [text_scores[\"neg\"], text_scores[\"neu\"],\n",
    "                           text_scores[\"pos\"], text_scores[\"compound\"]]\n",
    "        score = np.array([text_scores_lst])\n",
    "        if choice == -1:\n",
    "            padded_comment = sequence.pad_sequences([comment[2:]],maxlen=150)            \n",
    "        else:\n",
    "            padded_comment = sequence.pad_sequences([np.append(comment[2:],choice)],\n",
    "                                                    maxlen=150)\n",
    "        upvotes = upvote_model.predict([score, padded_comment])\n",
    "        choices.append((choice, upvotes))\n",
    "    return max(choices, key=itemgetter(1))[0]\n",
    "\n",
    "# Attempts to generate a seed threshold times, and returns the seed if successfully generated,\n",
    "# and returns the random seed otherwise\n",
    "def first_word_model_choice(parent_text, parent_sentiment_score, chain, model, threshold):\n",
    "    p_distribution = model.predict([np.array([parent_sentiment_score]) , np.array([parent_text])])[0]\n",
    "    i = 0\n",
    "    while i < threshold:\n",
    "        choice = np.random.choice(np.arange(p_distribution.shape[-1]), p=p_distribution)\n",
    "        if (0, choice) in chain:\n",
    "            return choice\n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load all models, data, words, and tokenizer\n",
    "upvote_model = keras.models.load_model(\"predict_upvotes.h5\")\n",
    "first_word_model = keras.models.load_model(\"predict_first_word.h5\")\n",
    "cluster_comments_model = joblib.load(open(\"cluster_comments.pkl\", 'rb'))\n",
    "cluster_markov_model = pickle.load(open(\"cluster_markov_model.pkl\", 'rb'))\n",
    "p_chain = pickle.load(open(\"generator_probability_chain.pkl\", 'rb'))\n",
    "\n",
    "comment_texts = np.load(\"comment_texts.npy\")\n",
    "comment_sentiment_scores = np.load(\"comment_sentiment_scores.npy\")\n",
    "words = pickle.load(open(\"words.pkl\", \"rb\"))\n",
    "inv_map = {v: k for k, v in words.items()}\n",
    "tokenizer = pickle.load(open(\"tokenizer.pkl\", \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "comment = damn even here you're everywhere\n",
      "\n",
      "reply = grep the term spyware like saying plagiarism is okay\n"
     ]
    }
   ],
   "source": [
    "# Using all the previously described models and data to generate a random comment reply.\n",
    "cmt = random.randint(0, comment_texts.shape[0])\n",
    "print(\"comment = {}\\n\".format(\n",
    "            \" \".join([inv_map[ind] for ind in [word for word in comment_texts[cmt] if word != 0]])))\n",
    "\n",
    "print(\"reply = {}\".format(generate_comment(comment_texts[cmt], comment_sentiment_scores[cmt],\n",
    "                                           inv_map, p_chain,\n",
    "                                           upvote_model=upvote_model,\n",
    "                                           first_word_model=first_word_model,\n",
    "                                           comment_cluster_model=cluster_comments_model,\n",
    "                                           cluster_markov_model=cluster_markov_model,\n",
    "                                           tokenizer=tokenizer\n",
    "                                           )\n",
    "                         )\n",
    "     )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
